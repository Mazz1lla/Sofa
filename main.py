# main.py (telebot-–≤–µ—Ä—Å–∏—è)
import telebot
import time
import threading
import json
import tempfile
import requests
import datetime
import openai  # Whisper API
import base64

from decision_engine import evaluate_response_timing, should_sofa_write_first
from responder import handle_incoming_message
from memory import update_short_memory, save_to_long_memory
from styler import split_message_to_chunks
from schedule_generator import generate_new_schedule
import pytz

moscow_tz = pytz.timezone("Europe/Moscow")

API_TOKEN = "8231992790:AAGiytsyqdj3QvTj7qIPbzYxRiUVm18fzFw"
USER_CHAT_ID = 1363075194  # –£–∫–∞–∂–∏—Ç–µ —Å–≤–æ–π chat_id

openai.api_key = "your_openai_key_here"  # üîê –£–∫–∞–∂–∏ —Å–≤–æ–π OpenAI –∫–ª—é—á

bot = telebot.TeleBot(API_TOKEN)

sofa_should_reply_pending = False

# üìÖ –ü–ª–∞–Ω–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è (–≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ)
def weekly_schedule_update_loop():
    while True:
        now = datetime.datetime.now(moscow_tz)
        if now.weekday() == 6 and now.hour == 22:  # –í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ 22:00
            with open("data/schedule.json", "r", encoding="utf-8") as f:
                old_schedule = json.load(f)
            new_schedule_json = generate_new_schedule(old_schedule)
            with open("data/schedule.json", "w", encoding="utf-8") as f:
                f.write(new_schedule_json)
            time.sleep(3600)
        time.sleep(60)

@bot.message_handler(content_types=['photo'])
def handle_photo(message):
    if message.chat.id != USER_CHAT_ID:
        bot.reply_to(message, "–ò–∑–≤–∏–Ω–∏—Ç–µ, –±–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
        return

    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª
        file_info = bot.get_file(message.photo[-1].file_id)
        file_url = f"https://api.telegram.org/file/bot{API_TOKEN}/{file_info.file_path}"
        response = requests.get(file_url)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as temp_file:
            temp_file.write(response.content)
            temp_file_path = temp_file.name

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Gemini —á–µ—Ä–µ–∑ OpenRouter
        from openai import OpenAI
        gemini = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key="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"
        )

        with open(temp_file_path, "rb") as img:
            image_data = base64.b64encode(img.read()).decode("utf-8")
            response = gemini.chat.completions.create(
                model="google/gemini-2.0-flash-001",
                messages=[
                    {"role": "user", "content": [
                        {"type": "text", "text": "–û–ø–∏—à–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ(–Ω–∞–ø—Ä–∏–º–µ—Ä, —É–∫–∞–∂–∏, –µ—Å–ª–∏ —ç—Ç–æ —Å–∫—Ä–∏–Ω—à–æ—Ç –∏–∑ –∫–∞–∫–æ–≥–æ-—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∞, —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å –∫–∞–∫–∏–º-–ª–∏–±–æ –∞–Ω–∏–º–µ)."},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                    ]}
                ]
            )

        description = response.choices[0].message.content.strip()
        summary = f"–ü–∞—Ä—Ç–Ω—ë—Ä –ø—Ä–∏—Å–ª–∞–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {description}"

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—Ä–∞—Ç–∫—É—é –ø–∞–º—è—Ç—å
        from memory import update_short_memory
        update_short_memory(summary, role="partner")

        # –°–æ—Ñ–∞ –æ—Ç–≤–µ—á–∞–µ—Ç –∫–∞–∫ –æ–±—ã—á–Ω–æ
        from decision_engine import evaluate_response_timing
        from responder import handle_incoming_message
        from styler import split_message_to_chunks
        from memory import save_to_long_memory

        delay, reason = evaluate_response_timing()
        should_reply = True
        global sofa_should_reply_pending
        sofa_should_reply_pending = should_reply
        if should_reply:
            time.sleep(delay)
            reply_text = handle_incoming_message(reason_activity=reason, delay_seconds=delay)
            chunks = split_message_to_chunks(reply_text)

            for chunk in chunks:
                if chunk["type"] == "text":
                    bot.send_chat_action(message.chat.id, "typing")
                    time.sleep(len(chunk["content"]) * 0.04)
                    bot.send_message(message.chat.id, chunk["content"])
                    sofa_should_reply_pending = False
                    update_short_memory(chunk["content"], role="sofa")
                elif chunk["type"] == "sticker":
                    bot.send_sticker(message.chat.id, chunk["sticker_id"])
                    sofa_should_reply_pending = False
                    update_short_memory("", role="sofa", is_sticker=True, sticker_description=chunk["description"])

            save_to_long_memory()

    except Exception as e:
        print("[‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ç–æ]", e)
        bot.reply_to(message, "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ üò¢")

# üé§ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@bot.message_handler(content_types=['voice'])
def handle_voice(message):
    if message.chat.id != USER_CHAT_ID:
        bot.reply_to(message, "–ò–∑–≤–∏–Ω–∏—Ç–µ, –±–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
        return

    try:
        file_info = bot.get_file(message.voice.file_id)
        file_url = f"https://api.telegram.org/file/bot{API_TOKEN}/{file_info.file_path}"
        response = requests.get(file_url)

        with tempfile.NamedTemporaryFile(delete=False, suffix=".ogg") as temp_file:
            temp_file.write(response.content)
            temp_file_path = temp_file.name

        with open(temp_file_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe("whisper-1", audio_file)

        text = transcript["text"]
        display_text = f"üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: {text}"
        update_short_memory(display_text, role="partner")

        delay, reason = evaluate_response_timing()
        should_reply = True
        global sofa_should_reply_pending
        sofa_should_reply_pending = should_reply
        if should_reply:
            time.sleep(delay)
            response = handle_incoming_message(reason_activity=reason, delay_seconds=delay)
            chunks = split_message_to_chunks(response)

            for chunk in chunks:
                if chunk["type"] == "text":
                    bot.send_chat_action(message.chat.id, "typing")
                    time.sleep(len(chunk["content"]) * 0.04)
                    bot.send_message(message.chat.id, chunk["content"])
                    sofa_should_reply_pending = False
                    update_short_memory(chunk["content"], role="sofa")
                elif chunk["type"] == "sticker":
                    bot.send_sticker(message.chat.id, chunk["sticker_id"])
                    sofa_should_reply_pending = False
                    update_short_memory("", role="sofa", is_sticker=True, sticker_description=chunk["description"])

            save_to_long_memory()

    except Exception as e:
        print("[‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è]", e)
        bot.reply_to(message, "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")

# üí¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@bot.message_handler(func=lambda message: True)
def handle_message(message):
    if message.chat.id != USER_CHAT_ID:
        bot.reply_to(message, "–ò–∑–≤–∏–Ω–∏—Ç–µ, –±–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
        return

    if message.text.startswith("/"):
        return

    reply_to_content = None
    if message.reply_to_message:
        reply_to_content = message.reply_to_message.text

    update_short_memory(message.text, role="partner", reply_to_content=reply_to_content)

    delay, reason = evaluate_response_timing()
    should_reply = True
    global sofa_should_reply_pending
    sofa_should_reply_pending = should_reply
    print("–û—Ç–≤–µ—Ç:", should_reply, delay, reason)
    if should_reply:
        time.sleep(delay)
        response = handle_incoming_message(reason_activity=reason, delay_seconds=delay)
        chunks = split_message_to_chunks(response)

        for chunk in chunks:
            if chunk["type"] == "text":
                bot.send_chat_action(message.chat.id, "typing")
                time.sleep(len(chunk["content"]) * 0.04)
                bot.send_message(message.chat.id, chunk["content"])
                sofa_should_reply_pending = False
                update_short_memory(chunk["content"], role="sofa")
            elif chunk["type"] == "sticker":
                bot.send_sticker(message.chat.id, chunk["sticker_id"])
                sofa_should_reply_pending = False
                update_short_memory("", role="sofa", is_sticker=True, sticker_description=chunk["description"])

        save_to_long_memory()

# ü§ñ –ü—Ä–æ–∞–∫—Ç–∏–≤–Ω–∞—è –°–æ—Ñ–∞
def proactive_sofa_loop():
    while True:
        time.sleep(1800)
        try:
            global sofa_should_reply_pending
            if sofa_should_reply_pending:
                continue  # –°–æ—Ñ–∞ –¥–æ–ª–∂–Ω–∞ —Å–Ω–∞—á–∞–ª–∞ –æ—Ç–≤–µ—Ç–∏—Ç—å ‚Äî –Ω–µ –ø–∏—à–µ—Ç —Å–∞–º–∞
            
            if should_sofa_write_first():
                text = handle_incoming_message(reason_activity="—Å–ø–æ–Ω—Ç–∞–Ω–Ω–æ–µ –∂–µ–ª–∞–Ω–∏–µ –Ω–∞–ø–∏—Å–∞—Ç—å üí¨", delay_seconds=0, is_proactive=True)
                chunks = split_message_to_chunks(text)
                for chunk in chunks:
                    if chunk["type"] == "text":
                        bot.send_chat_action(USER_CHAT_ID, "typing")
                        time.sleep(len(chunk["content"]) * 0.04)
                        bot.send_message(USER_CHAT_ID, chunk["content"])
                        update_short_memory(chunk["content"], role="sofa")
                    elif chunk["type"] == "sticker":
                        bot.send_sticker(USER_CHAT_ID, chunk["sticker_id"])
                        update_short_memory("", role="sofa", is_sticker=True, sticker_description=chunk["description"])
        except Exception as e:
            print("[‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ proactive_sofa_loop]", e)

# üßµ –ó–∞–ø—É—Å–∫ –≤ –ø–æ—Ç–æ–∫–∞—Ö
threading.Thread(target=proactive_sofa_loop, daemon=True).start()
threading.Thread(target=weekly_schedule_update_loop, daemon=True).start()

# üöÄ –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
while True:
    try:
        bot.infinity_polling(timeout=60, long_polling_timeout=30)
    except Exception as e:
        print(f"[‚ö†Ô∏è –ë–æ—Ç —É–ø–∞–ª —Å –æ—à–∏–±–∫–æ–π] {e}")
        time.sleep(5)
